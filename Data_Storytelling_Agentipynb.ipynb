{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ DATA STORYTELLING AGENT - FIXED VERSION ‚úÖ\n",
        "\n",
        "**Works with YouTube Transcript API v1.2.0+ and Google GenAI SDK**\n",
        "\n",
        "## üöÄ Quick Start:\n",
        "1. Run cells in order\n",
        "2. Add your API key in Step 3\n",
        "3. Generate posts!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 1: Install Packages"
      ],
      "metadata": {
        "id": "install_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest versions\n",
        "!pip install google-genai youtube-transcript-api --upgrade --quiet\n",
        "\n",
        "print(\"‚úÖ Packages installed successfully!\")\n",
        "print(\"\\nüìã Versions:\")\n",
        "!pip show google-genai | grep Version\n",
        "!pip show youtube-transcript-api | grep Version"
      ],
      "metadata": {
        "id": "install_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3afd3e6-b00e-4149-f127-72d417921311"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Packages installed successfully!\n",
            "\n",
            "üìã Versions:\n",
            "Version: 1.47.0\n",
            "Version: 1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Step 2: Import Libraries and Define Classes"
      ],
      "metadata": {
        "id": "import_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import logging\n",
        "import traceback\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "\n",
        "# YouTube Transcript API - FIXED imports (no TooManyRequests)\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api._errors import (\n",
        "    TranscriptsDisabled,\n",
        "    NoTranscriptFound,\n",
        "    VideoUnavailable,\n",
        "    YouTubeRequestFailed\n",
        ")\n",
        "\n",
        "# New Google GenAI SDK\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "import_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f3a705-0641-49b2-931a-c14a682f5a75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Step 3: Define Error Classes & Data Structures"
      ],
      "metadata": {
        "id": "structures_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ERROR CLASSES\n",
        "# ============================================================================\n",
        "\n",
        "class DataStorytellingError(Exception):\n",
        "    \"\"\"Base exception\"\"\"\n",
        "    pass\n",
        "\n",
        "class TranscriptExtractionError(DataStorytellingError):\n",
        "    \"\"\"Transcript error\"\"\"\n",
        "    pass\n",
        "\n",
        "class APIError(DataStorytellingError):\n",
        "    \"\"\"API error\"\"\"\n",
        "    pass\n",
        "\n",
        "class PostGenerationError(DataStorytellingError):\n",
        "    \"\"\"Post generation error\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA STRUCTURES\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class DataSource:\n",
        "    \"\"\"Verified data source\"\"\"\n",
        "    claim: str\n",
        "    source: str\n",
        "    reliability_score: float\n",
        "    context: str = \"\"\n",
        "\n",
        "@dataclass\n",
        "class StoryStructure:\n",
        "    \"\"\"Narrative structure\"\"\"\n",
        "    hook: str\n",
        "    context: str\n",
        "    revelation: str\n",
        "    consequences: str\n",
        "    data_sources: List[DataSource] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class SocialPost:\n",
        "    \"\"\"Social media post with metrics\"\"\"\n",
        "    platform: str\n",
        "    content: str\n",
        "    story_structure: StoryStructure\n",
        "    quality_score: float\n",
        "    data_reliability_score: float\n",
        "    audience_engagement_score: float\n",
        "    narrative_flow_score: float\n",
        "\n",
        "class Platform(Enum):\n",
        "    \"\"\"Platforms\"\"\"\n",
        "    INSTAGRAM = \"instagram\"\n",
        "    LINKEDIN = \"linkedin\"\n",
        "\n",
        "print(\"‚úÖ Error classes and data structures defined!\")"
      ],
      "metadata": {
        "id": "structures_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af37a13-5e58-4ace-a987-de49ab37bbad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Error classes and data structures defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé¨ Step 4: Transcript Extractor Class (FIXED)"
      ],
      "metadata": {
        "id": "transcript_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscriptExtractor:\n",
        "    \"\"\"Handles YouTube transcript extraction - FIXED for API v1.2.0+\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = logging.getLogger(__name__ + '.TranscriptExtractor')\n",
        "\n",
        "    def extract_video_id(self, url_or_id: str) -> str:\n",
        "        \"\"\"Extract video ID from URL\"\"\"\n",
        "        try:\n",
        "            if re.match(r'^[a-zA-Z0-9_-]{11}$', url_or_id):\n",
        "                return url_or_id\n",
        "\n",
        "            patterns = [\n",
        "                r'(?:youtube\\.com\\/watch\\?v=|youtu\\.be\\/)([a-zA-Z0-9_-]{11})',\n",
        "                r'youtube\\.com\\/embed\\/([a-zA-Z0-9_-]{11})',\n",
        "            ]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                match = re.search(pattern, url_or_id)\n",
        "                if match:\n",
        "                    return match.group(1)\n",
        "\n",
        "            raise TranscriptExtractionError(f\"Invalid video ID/URL: {url_or_id}\")\n",
        "        except Exception as e:\n",
        "            raise TranscriptExtractionError(f\"Failed to extract video ID: {str(e)}\")\n",
        "\n",
        "    def get_transcript(self, video_id: str, languages: List[str] = None) -> str:\n",
        "        \"\"\"\n",
        "        Get transcript - FIXED for new API structure\n",
        "\n",
        "        IMPORTANT: The new API (v1.2.0+) returns FetchedTranscript with .snippets\n",
        "        Each snippet has .text, .start, .duration attributes (NOT dictionary)\n",
        "        \"\"\"\n",
        "        if languages is None:\n",
        "            languages = ['en']\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Fetching transcript for: {video_id}\")\n",
        "\n",
        "            # Create API instance\n",
        "            api = YouTubeTranscriptApi()\n",
        "\n",
        "            # Fetch transcript - returns FetchedTranscript object\n",
        "            try:\n",
        "                fetched_transcript = api.fetch(video_id, languages=languages)\n",
        "                self.logger.info(f\"Got transcript in: {fetched_transcript.language}\")\n",
        "            except NoTranscriptFound:\n",
        "                self.logger.warning(f\"No transcript in {languages}, trying any language\")\n",
        "                fetched_transcript = api.fetch(video_id)\n",
        "                self.logger.info(f\"Using transcript in: {fetched_transcript.language}\")\n",
        "\n",
        "            # FIXED: Access snippets correctly\n",
        "            # OLD WAY (doesn't work): entry['text']\n",
        "            # NEW WAY (works): snippet.text\n",
        "            full_text = \" \".join([snippet.text for snippet in fetched_transcript.snippets])\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Transcript extracted: {len(full_text)} characters\")\n",
        "            self.logger.info(f\"‚úÖ Number of snippets: {len(fetched_transcript.snippets)}\")\n",
        "\n",
        "            return full_text\n",
        "\n",
        "        except TranscriptsDisabled:\n",
        "            raise TranscriptExtractionError(f\"Transcripts disabled for video {video_id}\")\n",
        "        except VideoUnavailable:\n",
        "            raise TranscriptExtractionError(f\"Video {video_id} is unavailable\")\n",
        "        except YouTubeRequestFailed as e:\n",
        "            raise TranscriptExtractionError(f\"YouTube request failed: {str(e)}\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Unexpected error: {str(e)}\\n{traceback.format_exc()}\"\n",
        "            self.logger.error(error_msg)\n",
        "            raise TranscriptExtractionError(error_msg)\n",
        "\n",
        "print(\"‚úÖ TranscriptExtractor class defined!\")"
      ],
      "metadata": {
        "id": "transcript_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0a8fbf-450e-4f81-aecf-72c848594988"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TranscriptExtractor class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ñ Step 5: Gemini API Client"
      ],
      "metadata": {
        "id": "gemini_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiClient:\n",
        "    \"\"\"Gemini API client using NEW SDK\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str = \"gemini-2.0-flash\"):\n",
        "        self.logger = logging.getLogger(__name__ + '.GeminiClient')\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "\n",
        "        try:\n",
        "            self.client = genai.Client(api_key=api_key)\n",
        "            self.logger.info(f\"‚úÖ Gemini client initialized: {model_name}\")\n",
        "\n",
        "            # Test API key\n",
        "            test_response = self.client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=\"Hello\",\n",
        "                config=types.GenerateContentConfig(max_output_tokens=10)\n",
        "            )\n",
        "            self.logger.info(\"‚úÖ API key validated\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise APIError(f\"Failed to initialize: {str(e)}\")\n",
        "\n",
        "    def generate_content(self, prompt: str, temperature: float = 0.7) -> str:\n",
        "        \"\"\"Generate content\"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Generating content...\")\n",
        "\n",
        "            response = self.client.models.generate_content(\n",
        "                model=self.model_name,\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    temperature=temperature,\n",
        "                    max_output_tokens=2048,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if hasattr(response, 'text'):\n",
        "                result = response.text\n",
        "            elif hasattr(response, 'candidates') and response.candidates:\n",
        "                result = response.candidates[0].content.parts[0].text\n",
        "            else:\n",
        "                raise APIError(\"Unexpected response format\")\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Generated: {len(result)} characters\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            raise APIError(f\"Generation failed: {str(e)}\")\n",
        "\n",
        "print(\"‚úÖ GeminiClient class defined!\")"
      ],
      "metadata": {
        "id": "gemini_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80b61c1-b577-4100-a8a7-c9f0cb4dcb59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GeminiClient class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Step 6: Data Storytelling Engine"
      ],
      "metadata": {
        "id": "engine_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataStorytellingEngine:\n",
        "    \"\"\"Creates data-driven stories\"\"\"\n",
        "\n",
        "    def __init__(self, gemini_client: GeminiClient):\n",
        "        self.client = gemini_client\n",
        "        self.logger = logging.getLogger(__name__ + '.Engine')\n",
        "\n",
        "    def analyze_transcript(self, transcript: str) -> StoryStructure:\n",
        "        \"\"\"Analyze transcript for story structure\"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Analyzing transcript...\")\n",
        "\n",
        "            prompt = f\"\"\"Analyze this transcript and extract a data story in JSON format.\n",
        "\n",
        "TRANSCRIPT:\n",
        "{transcript[:5000]}\n",
        "\n",
        "Return JSON only:\n",
        "{{\n",
        "    \"hook\": \"Attention-grabbing statement (1-2 sentences)\",\n",
        "    \"context\": \"Background (2-3 sentences)\",\n",
        "    \"revelation\": \"Key insight (1-2 sentences)\",\n",
        "    \"consequences\": \"Why it matters (2-3 sentences)\",\n",
        "    \"key_data_points\": [\n",
        "        {{\"claim\": \"specific claim\", \"source\": \"transcript\", \"context\": \"context\"}}\n",
        "    ]\n",
        "}}\n",
        "\n",
        "Requirements:\n",
        "- Focus on concrete data and facts\n",
        "- Make relevant to professionals 20-35\n",
        "- Ensure claims backed by transcript\"\"\"\n",
        "\n",
        "            response = self.client.generate_content(prompt, temperature=0.3)\n",
        "\n",
        "            # Parse JSON\n",
        "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
        "            if not json_match:\n",
        "                raise PostGenerationError(\"No JSON in response\")\n",
        "\n",
        "            data = json.loads(json_match.group(0))\n",
        "\n",
        "            # Create structure\n",
        "            data_sources = []\n",
        "            for dp in data.get('key_data_points', []):\n",
        "                data_sources.append(DataSource(\n",
        "                    claim=dp.get('claim', ''),\n",
        "                    source='transcript',\n",
        "                    reliability_score=0.9,\n",
        "                    context=dp.get('context', '')\n",
        "                ))\n",
        "\n",
        "            structure = StoryStructure(\n",
        "                hook=data.get('hook', ''),\n",
        "                context=data.get('context', ''),\n",
        "                revelation=data.get('revelation', ''),\n",
        "                consequences=data.get('consequences', ''),\n",
        "                data_sources=data_sources\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Analyzed: {len(data_sources)} data points\")\n",
        "            return structure\n",
        "\n",
        "        except Exception as e:\n",
        "            raise PostGenerationError(f\"Analysis failed: {str(e)}\")\n",
        "\n",
        "    def generate_post(self, story: StoryStructure, platform: Platform) -> SocialPost:\n",
        "        \"\"\"Generate social media post\"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Generating {platform.value} post...\")\n",
        "\n",
        "            if platform == Platform.INSTAGRAM:\n",
        "                guidelines = \"\"\"Platform: Instagram\n",
        "Tone: Casual, engaging\n",
        "Length: 150-200 words\n",
        "Emojis: 2-3\n",
        "Format: Short paragraphs\"\"\"\n",
        "            else:\n",
        "                guidelines = \"\"\"Platform: LinkedIn\n",
        "Tone: Professional\n",
        "Length: 200-300 words\n",
        "Emojis: None\n",
        "Format: Professional paragraphs\"\"\"\n",
        "\n",
        "            data_text = \"\\n\".join([f\"- {ds.claim}\" for ds in story.data_sources[:3]])\n",
        "\n",
        "            prompt = f\"\"\"Create a compelling social media post.\n",
        "\n",
        "{guidelines}\n",
        "\n",
        "STORY:\n",
        "Hook: {story.hook}\n",
        "Context: {story.context}\n",
        "Revelation: {story.revelation}\n",
        "Consequences: {story.consequences}\n",
        "\n",
        "DATA:\n",
        "{data_text}\n",
        "\n",
        "Requirements:\n",
        "1. Start with hook\n",
        "2. Build context\n",
        "3. Deliver revelation\n",
        "4. End with consequences\n",
        "5. Back all claims with data\n",
        "6. Storytelling format\n",
        "7. Target: professionals 20-35\n",
        "\n",
        "Write the post:\"\"\"\n",
        "\n",
        "            content = self.client.generate_content(prompt, temperature=0.7)\n",
        "            scores = self._calculate_scores(content, story, platform)\n",
        "\n",
        "            post = SocialPost(\n",
        "                platform=platform.value,\n",
        "                content=content,\n",
        "                story_structure=story,\n",
        "                quality_score=scores['overall'],\n",
        "                data_reliability_score=scores['data'],\n",
        "                audience_engagement_score=scores['engagement'],\n",
        "                narrative_flow_score=scores['flow']\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Generated: Quality {post.quality_score:.1f}%\")\n",
        "            return post\n",
        "\n",
        "        except Exception as e:\n",
        "            raise PostGenerationError(f\"Post generation failed: {str(e)}\")\n",
        "\n",
        "    def _calculate_scores(self, content: str, story: StoryStructure, platform: Platform) -> Dict[str, float]:\n",
        "        \"\"\"Calculate quality scores\"\"\"\n",
        "        data_score = min(100, len(story.data_sources) * 30)\n",
        "        word_count = len(content.split())\n",
        "        target = (150, 200) if platform == Platform.INSTAGRAM else (200, 300)\n",
        "        engagement = 90 if target[0] <= word_count <= target[1] else 70\n",
        "\n",
        "        flow = 0\n",
        "        if story.hook.lower()[:20] in content.lower():\n",
        "            flow += 25\n",
        "        if any(w in content.lower() for w in ['because', 'so', \"that's why\"]):\n",
        "            flow += 25\n",
        "        if story.revelation.lower()[:20] in content.lower():\n",
        "            flow += 25\n",
        "        if any(w in content.lower() for w in ['matter', 'important', 'means']):\n",
        "            flow += 25\n",
        "\n",
        "        overall = (data_score + engagement + flow) / 3\n",
        "\n",
        "        return {\n",
        "            'overall': overall,\n",
        "            'data': data_score,\n",
        "            'engagement': engagement,\n",
        "            'flow': flow\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ DataStorytellingEngine class defined!\")"
      ],
      "metadata": {
        "id": "engine_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a55bae0-447e-4cb3-922c-05e2590a0c0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ DataStorytellingEngine class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Step 7: Main Agent Class"
      ],
      "metadata": {
        "id": "agent_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataStorytellingAgent:\n",
        "    \"\"\"Main agent orchestrating everything\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str = \"gemini-2.0-flash\"):\n",
        "        self.logger = logging.getLogger(__name__ + '.Agent')\n",
        "        self.logger.info(\"=\"*70)\n",
        "        self.logger.info(\"INITIALIZING DATA STORYTELLING AGENT\")\n",
        "        self.logger.info(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            self.transcript_extractor = TranscriptExtractor()\n",
        "            self.gemini_client = GeminiClient(api_key, model_name)\n",
        "            self.engine = DataStorytellingEngine(self.gemini_client)\n",
        "            self.logger.info(\"‚úÖ All components initialized\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Initialization failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def create_posts_from_video(\n",
        "        self,\n",
        "        video_url_or_id: str,\n",
        "        platforms: List[Platform] = None,\n",
        "        languages: List[str] = None\n",
        "    ) -> Dict[str, SocialPost]:\n",
        "        \"\"\"Create posts from video\"\"\"\n",
        "        if platforms is None:\n",
        "            platforms = [Platform.INSTAGRAM, Platform.LINKEDIN]\n",
        "        if languages is None:\n",
        "            languages = ['en']\n",
        "\n",
        "        self.logger.info(\"\\n\" + \"=\"*70)\n",
        "        self.logger.info(\"STARTING POST GENERATION\")\n",
        "        self.logger.info(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Extract ID\n",
        "            self.logger.info(\"\\nSTEP 1: Extracting video ID...\")\n",
        "            video_id = self.transcript_extractor.extract_video_id(video_url_or_id)\n",
        "            self.logger.info(f\"‚úÖ Video ID: {video_id}\")\n",
        "\n",
        "            # Step 2: Get transcript\n",
        "            self.logger.info(\"\\nSTEP 2: Fetching transcript...\")\n",
        "            transcript = self.transcript_extractor.get_transcript(video_id, languages)\n",
        "            self.logger.info(f\"‚úÖ Transcript: {len(transcript)} characters\")\n",
        "\n",
        "            # Step 3: Analyze\n",
        "            self.logger.info(\"\\nSTEP 3: Analyzing transcript...\")\n",
        "            story = self.engine.analyze_transcript(transcript)\n",
        "            self.logger.info(f\"‚úÖ Found {len(story.data_sources)} data sources\")\n",
        "\n",
        "            # Step 4: Generate posts\n",
        "            self.logger.info(\"\\nSTEP 4: Generating posts...\")\n",
        "            posts = {}\n",
        "            for platform in platforms:\n",
        "                post = self.engine.generate_post(story, platform)\n",
        "                posts[platform.value] = post\n",
        "                self.logger.info(f\"  ‚úÖ {platform.value}: {post.quality_score:.1f}%\")\n",
        "\n",
        "            self.logger.info(\"\\n\" + \"=\"*70)\n",
        "            self.logger.info(\"‚úÖ ALL POSTS GENERATED SUCCESSFULLY!\")\n",
        "            self.logger.info(\"=\"*70)\n",
        "\n",
        "            return posts\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"\\n‚ùå ERROR: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "print(\"‚úÖ DataStorytellingAgent class defined!\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ ALL CLASSES LOADED - READY TO USE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "agent_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21352ced-c933-4c12-f449-ff7cb0bd0158"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ DataStorytellingAgent class defined!\n",
            "\n",
            "======================================================================\n",
            "üéâ ALL CLASSES LOADED - READY TO USE!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Step 8: Configure Your API Key\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT:** Replace `YOUR_API_KEY_HERE` with your actual Gemini API key!\n",
        "\n",
        "Get your key here: https://aistudio.google.com/app/apikey"
      ],
      "metadata": {
        "id": "config_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ö†Ô∏è REPLACE THIS WITH YOUR ACTUAL API KEY!\n",
        "GEMINI_API_KEY = \" \"\n",
        "\n",
        "# Model selection\n",
        "MODEL_NAME = \"gemini-2.0-flash\"  # Fast and efficient\n",
        "# Alternative: \"gemini-2.5-pro\" for highest quality\n",
        "\n",
        "# Validate API key format\n",
        "if GEMINI_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"‚ùå ERROR: Please replace YOUR_API_KEY_HERE with your actual API key!\")\n",
        "    print(\"\\nüìç Get your key here: https://aistudio.google.com/app/apikey\")\n",
        "elif not GEMINI_API_KEY.startswith(\"AIzaSy\"):\n",
        "    print(\"‚ö†Ô∏è WARNING: Your API key doesn't look correct.\")\n",
        "    print(\"   Gemini API keys typically start with 'AIzaSy'\")\n",
        "else:\n",
        "    print(\"‚úÖ API key configured!\")\n",
        "    print(f\"‚úÖ Using model: {MODEL_NAME}\")"
      ],
      "metadata": {
        "id": "config_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978ca8a1-35cf-4d23-a9c4-3f0c19c722bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key configured!\n",
            "‚úÖ Using model: gemini-2.0-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Step 9: Test with a Video\n",
        "\n",
        "Run this cell to generate your first posts! üéâ"
      ],
      "metadata": {
        "id": "test_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verified working video IDs\n",
        "VIDEO_ID = \"Ks-_Mh1QhMc\"  # Simon Sinek - How great leaders inspire action\n",
        "# Other options:\n",
        "# VIDEO_ID = \"Ks-_Mh1QhMc\"  # Amy Cuddy - Body Language\n",
        "# VIDEO_ID = \"arj7oStGLkU\"  # Tim Urban - Procrastination\n",
        "\n",
        "try:\n",
        "    print(\"\\nüöÄ Initializing agent...\\n\")\n",
        "    agent = DataStorytellingAgent(api_key=GEMINI_API_KEY, model_name=MODEL_NAME)\n",
        "\n",
        "    print(\"\\nüìù Generating posts...\\n\")\n",
        "    posts = agent.create_posts_from_video(\n",
        "        video_url_or_id=VIDEO_ID,\n",
        "        platforms=[Platform.INSTAGRAM, Platform.LINKEDIN],\n",
        "        languages=['en']\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for platform_name, post in posts.items():\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"üì± {platform_name.upper()} POST\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"\\nüìä Quality Scores:\")\n",
        "        print(f\"   Overall:          {post.quality_score:.1f}%\")\n",
        "        print(f\"   Data Reliability: {post.data_reliability_score:.1f}%\")\n",
        "        print(f\"   Engagement:       {post.audience_engagement_score:.1f}%\")\n",
        "        print(f\"   Narrative Flow:   {post.narrative_flow_score:.1f}%\")\n",
        "        print(f\"\\nüìù Content:\\n\")\n",
        "        print(post.content)\n",
        "        print(f\"\\n{'='*70}\")\n",
        "\n",
        "    print(\"\\n‚úÖ SUCCESS! All posts generated perfectly!\\n\")\n",
        "\n",
        "except TranscriptExtractionError as e:\n",
        "    print(f\"\\n‚ùå TRANSCRIPT ERROR: {e}\")\n",
        "    print(\"\\nüí° Solutions:\")\n",
        "    print(\"   1. Try a different video ID\")\n",
        "    print(\"   2. Use verified IDs: u4ZoJKF_VuA, Ks-_Mh1QhMc, arj7oStGLkU\")\n",
        "    print(\"   3. Make sure video has captions enabled\")\n",
        "\n",
        "except APIError as e:\n",
        "    print(f\"\\n‚ùå API ERROR: {e}\")\n",
        "    print(\"\\nüí° Solutions:\")\n",
        "    print(\"   1. Check your API key is correct\")\n",
        "    print(\"   2. Get key: https://aistudio.google.com/app/apikey\")\n",
        "    print(\"   3. Make sure key starts with 'AIzaSy'\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå UNEXPECTED ERROR: {e}\")\n",
        "    print(f\"\\n{traceback.format_exc()}\")"
      ],
      "metadata": {
        "id": "test_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e45efed-210e-47e4-fcd2-a2237158885d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Initializing agent...\n",
            "\n",
            "\n",
            "üìù Generating posts...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üìä RESULTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üì± INSTAGRAM POST\n",
            "======================================================================\n",
            "\n",
            "üìä Quality Scores:\n",
            "   Overall:          76.7%\n",
            "   Data Reliability: 90.0%\n",
            "   Engagement:       90.0%\n",
            "   Narrative Flow:   50.0%\n",
            "\n",
            "üìù Content:\n",
            "\n",
            "ü§Ø Did you know your body language speaks volumes, even before you utter a single word? That handshake, that glance ‚Äì they're all being analyzed! Social scientists have been digging into this for years, and the results are mind-blowing.\n",
            "\n",
            "Turns out, how we carry ourselves *seriously* impacts how people judge us, and these judgments can predict some pretty big stuff. Think hiring decisions, negotiation success, even how well your doctor gets along with patients! ü©∫\n",
            "\n",
            "Here's the kicker: it's not just about how others see you. Our nonverbal cues actually affect *our own* thoughts, feelings, and even our physiology! Power posing, anyone? üí™\n",
            "\n",
            "So, what's the takeaway? Understanding and leveraging your nonverbal communication can be a game-changer in your career. Research shows that judgments from 30-second clips of doctor-patient interactions can predict lawsuits, and a one-second glance at a political candidate's face can predict 70% of election outcomes! Even emoticons in online negotiations can help you claim more value. Bottom line: master your body language, master your impact! #bodylanguage #communication #careergoals #nonverbalcommunication\n",
            "\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üì± LINKEDIN POST\n",
            "======================================================================\n",
            "\n",
            "üìä Quality Scores:\n",
            "   Overall:          93.3%\n",
            "   Data Reliability: 90.0%\n",
            "   Engagement:       90.0%\n",
            "   Narrative Flow:   100.0%\n",
            "\n",
            "üìù Content:\n",
            "\n",
            "Did you know that a single handshake can spark weeks of conversation and analysis? Nonverbal communication significantly impacts our lives, influencing judgments and shaping outcomes in both professional and personal settings. It's more than just polite gestures; it's a powerful, often subconscious, form of communication.\n",
            "\n",
            "Social scientists have spent decades studying the profound effects of body language. These studies reveal that snap judgments based on nonverbal cues can predict meaningful life outcomes. Consider this: judgments gleaned from just 30-second soundless clips of physician-patient interactions can predict the likelihood of that physician being sued. Even more striking, assessments of political candidates' faces in a single second can predict 70% of U.S. Senate and gubernatorial race outcomes. The power of nonverbal communication is undeniable.\n",
            "\n",
            "But here's the revelation: our nonverbal expressions not only influence how others perceive us, but they also affect our own thoughts, feelings, and even our physiology. This means we have the potential to consciously shape our internal state by adjusting our external presentation.\n",
            "\n",
            "Understanding and leveraging nonverbal cues can be a game-changer in the professional world. Adopting powerful postures, for example, can enhance confidence and project authority. Using emoticons strategically in online negotiations can even lead to claiming more value. By consciously cultivating our nonverbal communication skills, we can enhance our professional interactions, improve negotiation outcomes, and develop a stronger leadership presence. What are your experiences with nonverbal communication in the workplace? Share your thoughts in the comments below.\n",
            "\n",
            "\n",
            "======================================================================\n",
            "\n",
            "‚úÖ SUCCESS! All posts generated perfectly!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J02H1vmFLD8O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 10: Save Posts to Files (Optional)"
      ],
      "metadata": {
        "id": "save_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save posts to text files\n",
        "# Works with either 'posts' from Step 9 or 'my_posts' from Step 11\n",
        "try:\n",
        "    # Try to find posts from either test cell\n",
        "    if 'my_posts' in locals():\n",
        "        posts_to_save = my_posts\n",
        "    elif 'posts' in locals():\n",
        "        posts_to_save = posts\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No posts to save yet!\")\n",
        "        print(\"üí° Run Step 9 or Step 11 first to generate posts\")\n",
        "        posts_to_save = None\n",
        "\n",
        "    if posts_to_save:\n",
        "        for platform_name, post in posts_to_save.items():\n",
        "            filename = f\"{platform_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"Platform: {platform_name}\\n\")\n",
        "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "                f.write(f\"Quality Score: {post.quality_score:.1f}%\\n\")\n",
        "                f.write(f\"\\n{'-' * 70}\\n\\n\")\n",
        "                f.write(post.content)\n",
        "                f.write(f\"\\n\\n{'-' * 70}\\n\")\n",
        "                f.write(f\"\\nData Sources: {len(post.story_structure.data_sources)}\\n\")\n",
        "\n",
        "            print(f\"‚úÖ Saved {platform_name} post to: {filename}\")\n",
        "\n",
        "            # Download files (works in Colab)\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                files.download(filename)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(\"\\n‚úÖ All posts saved successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving files: {str(e)}\")"
      ],
      "metadata": {
        "id": "save_cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "eeb3bf6b-6375-41a5-b248-fd83441aa80e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved instagram post to: instagram_20251029_230914.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24607183-7932-450c-bc9b-84122e4c06e5\", \"instagram_20251029_230914.txt\", 1401)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved linkedin post to: linkedin_20251029_230914.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7fba2ae8-68ed-4255-960e-36a5021e6b04\", \"linkedin_20251029_230914.txt\", 1960)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ All posts saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® Step 11: Customize for Your Own Videos"
      ],
      "metadata": {
        "id": "custom_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to generate posts for YOUR videos\n",
        "\n",
        "# Replace with your video URL or ID\n",
        "MY_VIDEO = \"YOUR_VIDEO_ID_OR_URL_HERE\"\n",
        "\n",
        "# Choose platforms\n",
        "MY_PLATFORMS = [Platform.INSTAGRAM, Platform.LINKEDIN]\n",
        "# Or just one: MY_PLATFORMS = [Platform.INSTAGRAM]\n",
        "\n",
        "# Choose languages (tries in order)\n",
        "MY_LANGUAGES = ['en']  # English\n",
        "# Or: MY_LANGUAGES = ['en', 'es']  # Try English, then Spanish\n",
        "\n",
        "# Generate posts\n",
        "if MY_VIDEO != \"YOUR_VIDEO_ID_OR_URL_HERE\":\n",
        "    try:\n",
        "        print(f\"\\nüé¨ Processing: {MY_VIDEO}\\n\")\n",
        "\n",
        "        my_posts = agent.create_posts_from_video(\n",
        "            video_url_or_id=MY_VIDEO,\n",
        "            platforms=MY_PLATFORMS,\n",
        "            languages=MY_LANGUAGES\n",
        "        )\n",
        "\n",
        "        # Show results\n",
        "        for platform_name, post in my_posts.items():\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"üì± {platform_name.upper()}\")\n",
        "            print(f\"{'='*70}\")\n",
        "            print(f\"Quality: {post.quality_score:.1f}%\\n\")\n",
        "            print(post.content)\n",
        "            print(f\"\\n{'='*70}\")\n",
        "\n",
        "        print(\"\\n‚úÖ Your custom posts are ready!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
        "        print(\"\\nüí° Tips:\")\n",
        "        print(\"   ‚Ä¢ Make sure video has transcripts\")\n",
        "        print(\"   ‚Ä¢ Try a verified video ID first\")\n",
        "        print(\"   ‚Ä¢ Check error message above\")\n",
        "else:\n",
        "    print(\"üí° Replace MY_VIDEO with your video ID or URL to generate posts!\")"
      ],
      "metadata": {
        "id": "custom_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe01455-5993-4aef-a2f3-50a0d141fd5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí° Replace MY_VIDEO with your video ID or URL to generate posts!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Verified Working Videos\n",
        "\n",
        "Copy these video IDs to test (confirmed working):"
      ],
      "metadata": {
        "id": "videos_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VERIFIED_VIDEOS = {\n",
        "    \"TED Talks\": {\n",
        "        \"u4ZoJKF_VuA\": \"Simon Sinek - How great leaders inspire action\",\n",
        "        \"Ks-_Mh1QhMc\": \"Amy Cuddy - Your body language shapes who you are\",\n",
        "        \"arj7oStGLkU\": \"Tim Urban - Inside the mind of a procrastinator\",\n",
        "    },\n",
        "    \"Educational\": {\n",
        "        \"aircAruvnKk\": \"3Blue1Brown - What is a neural network?\",\n",
        "        \"GiPe1OiKQuk\": \"Crash Course - Intro to Machine Learning\",\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üì∫ VERIFIED WORKING VIDEO IDs:\\n\")\n",
        "for category, videos in VERIFIED_VIDEOS.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for video_id, description in videos.items():\n",
        "        print(f\"  ‚Ä¢ {video_id}\")\n",
        "        print(f\"    {description}\")\n",
        "        print(f\"    https://youtube.com/watch?v={video_id}\")"
      ],
      "metadata": {
        "id": "videos_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddefc6b4-1db6-4cea-9025-00a82d12564e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∫ VERIFIED WORKING VIDEO IDs:\n",
            "\n",
            "\n",
            "TED Talks:\n",
            "  ‚Ä¢ u4ZoJKF_VuA\n",
            "    Simon Sinek - How great leaders inspire action\n",
            "    https://youtube.com/watch?v=u4ZoJKF_VuA\n",
            "  ‚Ä¢ Ks-_Mh1QhMc\n",
            "    Amy Cuddy - Your body language shapes who you are\n",
            "    https://youtube.com/watch?v=Ks-_Mh1QhMc\n",
            "  ‚Ä¢ arj7oStGLkU\n",
            "    Tim Urban - Inside the mind of a procrastinator\n",
            "    https://youtube.com/watch?v=arj7oStGLkU\n",
            "\n",
            "Educational:\n",
            "  ‚Ä¢ aircAruvnKk\n",
            "    3Blue1Brown - What is a neural network?\n",
            "    https://youtube.com/watch?v=aircAruvnKk\n",
            "  ‚Ä¢ GiPe1OiKQuk\n",
            "    Crash Course - Intro to Machine Learning\n",
            "    https://youtube.com/watch?v=GiPe1OiKQuk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéâ You're Done!\n",
        "\n",
        "### Next Steps:\n",
        "1. **Customize the tone** - Edit the prompts in Step 6\n",
        "2. **Use your videos** - Add your video IDs in Step 11\n",
        "3. **Automate** - Schedule this to run weekly\n",
        "4. **Scale up** - Process multiple videos at once\n",
        "5. **Make it billingual** - Accept both Spanish and English inputs and outputs, or translate Spanish to English for post generation\n",
        "6. **Iterations** - Add more layers of self-criticism and higher benchmarks of quality\n",
        "### Tips:\n",
        "- Posts with 70%+ quality are ready to publish\n",
        "- Always review before posting\n",
        "- Add your personal touch to the AI-generated content\n",
        "- Test different videos to see what works best\n",
        "\n",
        "### Need Help?\n",
        "- **API Key:** https://aistudio.google.com/app/apikey\n",
        "- **Docs:** https://googleapis.github.io/python-genai/\n",
        "- **YouTube API:** https://github.com/jdepoix/youtube-transcript-api\n",
        "\n",
        "---\n",
        "\n",
        "**üéä Happy Automating!**\n",
        "\n",
        "*This notebook uses the FIXED version that works with youtube-transcript-api v1.2.0+*"
      ],
      "metadata": {
        "id": "done_section"
      }
    }
  ]
}
